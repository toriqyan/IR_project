{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3923\n"
     ]
    }
   ],
   "source": [
    "# with open('dataset/business_LV.json') as fd:\n",
    "#     df = json.load(fd)\n",
    "# print(len(df))\n",
    "df = pd.read_csv('dataset/business_LV.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [\"business_id\", \"neighborhood\", \"stars\", \"review_count\", \n",
    "#             \"RestaurantsTakeOut\", \"GoodForKids\", \"RestaurantsGoodForGroups\", \n",
    "#             \"RestaurantsReservations\",\"DriveThru\", \"WiFi\",\"BusinessParking\", \"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variables(all_columns,mode):\n",
    "    cols = all_columns\n",
    "    cat_cols = [\"neighborhood\", \"RestaurantsTakeOut\", \"GoodForKids\", \"RestaurantsGoodForGroups\",\"RestaurantsReservations\",\"DriveThru\", \"WiFi\",\"BusinessParking\", \"categories\"]\n",
    "    if mode == \"cat\":\n",
    "        cols = [\"neighborhood\", \"categories\"]\n",
    "    elif mode == \"bool\":\n",
    "        cols = [\"RestaurantsTakeOut\", \"GoodForKids\", \"RestaurantsGoodForGroups\",\"RestaurantsReservations\",\"DriveThru\", \"WiFi\",\"BusinessParking\"]\n",
    "    elif mode == \"cont\":\n",
    "        cols = ['stars', 'review_count']\n",
    "    print(cols)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neighborhood', 'categories']\n"
     ]
    }
   ],
   "source": [
    "# def format_long_data_cat(df,cols_to_feat,time):\n",
    "    #First 6 hours\n",
    "cols_to_feat = []\n",
    "new_df = df.copy()\n",
    "new_df = new_df.sort_values(['business_id'])\n",
    "id_list = sorted(list(set(list(new_df['business_id']))))\n",
    "cols = variables(new_df.columns,\"cat\")\n",
    "\n",
    "for id in id_list:\n",
    "    temp = new_df[new_df['business_id']==id]\n",
    "    for idx,row in temp.iterrows():\n",
    "        for col in cols:\n",
    "            if (col == 'categories'):\n",
    "                options = ast.literal_eval(row[col])\n",
    "                for option in options:\n",
    "                    if (option != \"Restaurants\" and option not in cols_to_feat):\n",
    "                        cols_to_feat.append(option)\n",
    "            else:\n",
    "                suffix = row[col]\n",
    "                if (type(suffix) is float and math.isnan(suffix)):\n",
    "                    suffix = \"missing\"\n",
    "                else:\n",
    "                    suffix = row[col]\n",
    "                if (col+'_'+suffix) not in cols_to_feat:\n",
    "                    cols_to_feat.append(col+'_'+suffix)\n",
    "# print(cols_to_feat)\n",
    "\n",
    "\n",
    "#     ###CREATE DICTIONARY###\n",
    "    \n",
    "#     i = 0\n",
    "#     for col in cols:\n",
    "#         for j in range(i, i + 6):\n",
    "#             if col == 'location':\n",
    "#                 cols_to_feat[j] = col + location_suffix[j - i]\n",
    "#             else:\n",
    "#                 cols_to_feat[j] = col + suffix[j - i]\n",
    "#         i += 6\n",
    "    \n",
    "#     for k,v in cols_to_feat.items():\n",
    "#         if v == 'location_GarbageColumn':\n",
    "#             del cols_to_feat[k]\n",
    "#             break\n",
    "#     ###CREATE DICTIONARY###\n",
    "        \n",
    "#     cat_arr = np.zeros((len(id_list),len(cols),6))\n",
    "#     dic = {'LL':[1,0,0,0,0,0],'L':[0,1,0,0,0,0],'N':[0,0,1,0,0,0],'H':[0,0,0,1,0,0],'HH':[0,0,0,0,1,0],'A':[1,0,0,0,0,0]}\n",
    "#     loc_dic = {'ED':[1,0,0,0,0,0],'ICU':[0,1,0,0,0,0],'floor':[0,0,1,0,0,0],'Procedure':[0,0,0,1,0,0]}\n",
    "#     i = 0\n",
    "#     for id in id_list:\n",
    "#         temp = new_df3[new_df3['id']==id]\n",
    "#         patient_feature_vector = np.zeros((len(cols),6))\n",
    "#         j = 0\n",
    "#         for c in cols:\n",
    "#             column_vector = np.zeros(6)\n",
    "#             for idx,row in temp.iterrows():\n",
    "#                 if (c == 'location'):\n",
    "#                     #Location is known\n",
    "#                     if (not type(row[c]) is float):\n",
    "#                         column_vector = np.logical_or(column_vector,loc_dic[row[c]]).astype(int)\n",
    "#                     #Location is unknown\n",
    "#                     else:\n",
    "#                         column_vector[4] = 1\n",
    "#                 #If continuous entry exists\n",
    "#                 elif not math.isnan(row[c[:-5]]):\n",
    "#                     #Normal level: N\n",
    "#                     if (type(row[c]) is float):\n",
    "#                         column_vector = np.logical_or(column_vector,dic['N']).astype(int)\n",
    "#                     #Abnormal level: LL,L,H,HH\n",
    "#                     else:\n",
    "#                         column_vector = np.logical_or(column_vector,dic[row[c]]).astype(int)\n",
    "#                 #If data is missing\n",
    "#                 else:\n",
    "#                     column_vector[5] =  1\n",
    "\n",
    "#             if (sum(column_vector[:5]) and column_vector[5]):\n",
    "#                 column_vector[5] = 0\n",
    "\n",
    "#             patient_feature_vector[j] = column_vector.astype(int)\n",
    "#             j += 1\n",
    "\n",
    "#         cat_arr[i] = patient_feature_vector\n",
    "#         i += 1\n",
    "    \n",
    "#     print('FINISHED CATEGORICAL VARIABLES!')\n",
    "#     #Make it 2D\n",
    "#     cat_arr = np.reshape(cat_arr,(cat_arr.shape[0],-1))\n",
    "#     #Remove column of zeros caused by location\n",
    "#     cat_arr = cat_arr[:,:-1]\n",
    "\n",
    "#     return cat_arr,cols_to_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3923, 374)\n"
     ]
    }
   ],
   "source": [
    "cat_arr = np.zeros((len(id_list),len(cols_to_feat)))\n",
    "print(cat_arr.shape)\n",
    "i = 0\n",
    "for id in id_list:\n",
    "    temp = new_df[new_df['business_id']==id]\n",
    "    feature_vector = np.zeros((len(cols_to_feat)))\n",
    "    j = 0\n",
    "    for col in cols:\n",
    "        if (col == \"categories\"):\n",
    "            options = ast.literal_eval(row[col])\n",
    "            for option in options:\n",
    "                if (option != \"Restaurants\"):\n",
    "                    feature_vector[cols_to_feat.index(option)] = 1\n",
    "        else:\n",
    "            suffix = row[col]\n",
    "            if (type(suffix) is float and math.isnan(suffix)):\n",
    "                suffix = \"missing\"\n",
    "            else:\n",
    "                suffix = row[col]\n",
    "            feature_vector[cols_to_feat.index(col+'_'+suffix)] = 1\n",
    "    cat_arr[i] = feature_vector\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RestaurantsTakeOut', 'GoodForKids', 'RestaurantsGoodForGroups', 'RestaurantsReservations', 'DriveThru', 'WiFi', 'BusinessParking']\n",
      "[ 1.  1.  1.  0.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "cols = variables(new_df.columns,\"bool\")\n",
    "for col in cols:\n",
    "    cols_to_feat.append(col)\n",
    "bool_arr = np.zeros((len(id_list), len(cols)))\n",
    "i = 0\n",
    "for id in id_list:\n",
    "    temp = new_df[new_df['business_id']==id]\n",
    "    feature_vector = np.zeros((len(cols)))\n",
    "    j = 0\n",
    "    for col in cols:\n",
    "        if bool(row[col]):\n",
    "            feature_vector[cols.index(col)] = 1\n",
    "    bool_arr[i] = feature_vector\n",
    "    i+=1\n",
    "print(bool_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stars', 'review_count']\n"
     ]
    }
   ],
   "source": [
    "cols= variables(new_df.columns, \"cont\")\n",
    "li1 = []\n",
    "for c in total_cols:\n",
    "    for id in id_list:\n",
    "        if not flag:\n",
    "            li1.append(np.sum(new_df3[new_df3['id'] == id][c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
